{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inner-chester",
   "metadata": {},
   "source": [
    "# Data Science Task ðŸŒŽ (Connect Earth)\n",
    "\n",
    "To properly understand your skills, though-process and creativity as well as to allow you to get a feel for some of the data we work with, find below a short (1 hour) data science task! Please message nick@connect.earth if you have any questions!\n",
    "\n",
    "### Instructions:\n",
    "**1. Data Analysis (â‰ˆ20min)** - Just as with any data science task - first analyse the dataset, provide plots and give some basic underlying insights on the trends and spread of the data.\n",
    "\n",
    "**2. Outlier Detection (â‰ˆ20 min)** - For Scope 1, Scope 2 and Scope 3 some companies may be wrongly under-reporting or simply have very green initiatives. Please formulate and apply a way to spot outliers in the data and then remove those outliers. Provide a short explanation of your method and why.\n",
    "\n",
    "**3. Data Incompleteness/Prediction (â‰ˆ20 min)** - For several companies, there are gaps for certain sub-categories (Such as Scope 3 and Fugitive Emissions). Please decide on a data-filling approach, apply it and document your approach to filling in these incomplete cells. Note: using a standard filling technique with the median/mean may not work optimally in this scenario as companies also vary in other factors, so you may have to use a prediction model.\n",
    "\n",
    "\n",
    "### Completion:\n",
    "\n",
    "We are not neccessarily looking for your models to perfectly fit the data (as the data is half real, half sampled), instead we care much more about your approach and why you chose to take certain decisions. \n",
    "\n",
    "Please send over this completed Jupyter Notebook with your calculations and why you took those choices.\n",
    "\n",
    "\n",
    "### Data Set:\n",
    "\n",
    "[Here](https://drive.google.com/file/d/1uvJwGjpsmHPs2wAFQaJKQXwnel4Q0wI0/view?usp=sharing) we provide a minimised dataset with a mixture of real and sample data. Don't expect it to have perfect correlations, focus more on the methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-butterfly",
   "metadata": {},
   "source": [
    "# 0.) Import the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "df = pd.read_csv ('data-task.csv') \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-spine",
   "metadata": {},
   "source": [
    "# 1.) Data Analysis (â‰ˆ20min)\n",
    "\n",
    "Just as with any data science task - first analyse the dataset, provide plots and give some basic underlying insights on the trends and spread of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3826114-5e47-48ff-8861-65b7f9c1eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[1:]\n",
    "\n",
    "df[cols].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_small = ['scope 1 - Gases (mt CO2)', 'scope 2 - Electricity (mt CO2)',\n",
    "            'Employees', 'Fugitive Emissions (mt CO2)', 'Mobile Combustion (mt CO2)',\n",
    "            'Electricity Emissions (Location-based) - mt CO2', 'Stationary Combustion (mt CO2)',\n",
    "            'Electricity Emissions (Market-based) - mt CO2']\n",
    "\n",
    "cols_big = ['scope 3 - Other Indirect Emissions (mt CO2)', \n",
    "            'Revenue (GBP)', ]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8,12))\n",
    "\n",
    "sns.boxplot(data=df[cols_small], orient='h', ax = axes[0])\n",
    "sns.boxplot(data=df[cols_big], orient='h', ax = axes[1])\n",
    "\n",
    "axes[0].set_xlim(0, 1e6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-wings",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "\n",
    "First of all, I used the pandas `skew()` function to calculate the skewness of all variables. All of the variables are highly skewed, indicating the existence of outliers. After doing that, I created box plot graphs for all the variables. Due to the different scales, I created one for variables with relatively small values, and one for those that have bigger ones. The box plots further confirm that most of the variables have some outliers. I decided not to create histograms for the variables because there aren't enough rows on the dataset to get meaningful plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f523e7-dca7-43e4-b237-6ee344568e21",
   "metadata": {},
   "source": [
    "# 2. Data Incompleteness/Prediction (â‰ˆ20 min)\n",
    "\n",
    "For several companies, there are gaps for certain sub-categories (Such as Scope 3 and Fugitive Emissions). Please decide on a data-filling approach, apply it and document your approach to filling in these incomplete cells. Note: using a standard filling technique with the median/mean may not work optimally in this scenario as companies also vary in other factors (ex:size), you may have to use a prediction model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b021f94-1590-479a-896e-79422d67d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[1:]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "array = scaler.fit_transform(df[cols])\n",
    "array = imputer.fit_transform(array)\n",
    "array = scaler.inverse_transform(array)\n",
    "\n",
    "df_ = pd.DataFrame(array,columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6dc2f-263c-4aa3-a77e-3845dde84aec",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "I used the K-Nearest Neighbors imputer to fill the missing values. As it was noted, simple imputation techniques such as using the mean value wouldn't work on that dataset. The KNN imputer uses the mean value from the nearest neighbors of each row, making it a more advanced and robust imputation technique. I rearranged part 2 and 3, because the outlier detection algorithm wouldn't work with NaN values, so I had to apply the imputer first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-waterproof",
   "metadata": {},
   "source": [
    "# 3. Outlier Detection (â‰ˆ20 min)\n",
    "\n",
    "For Scope 1, Scope 2 and Scope 3 some companies may be wrongly under-reporting or simply have very green initiatives. Please formulate and apply a way to spot outliers in the data and then remove those outliers. Provide a short explanation of your method and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope1 = df_['scope 1 - Gases (mt CO2)'].to_numpy().reshape(-1, 1)\n",
    "scope2 = df_['scope 2 - Electricity (mt CO2)'].to_numpy().reshape(-1, 1)\n",
    "scope3 = df_['scope 3 - Other Indirect Emissions (mt CO2)'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "\n",
    "od1 = IsolationForest(contamination = 0.1).fit_predict(scope1)\n",
    "od2 = IsolationForest(contamination = 0.1).fit_predict(scope2)\n",
    "od3 = IsolationForest(contamination = 0.1).fit_predict(scope3)\n",
    "\n",
    "scope1 = scope1[np.where(od1 == 1, True, False)]\n",
    "scope2 = scope2[np.where(od2 == 1, True, False)]\n",
    "scope3 = scope3[np.where(od3 == 1, True, False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-destination",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "I used the Isolation Forest outlier detection algorithm to find the outliers for each variable. First of all, I created numpy arrays for columns scope 1-3. After doing that, I trained an Isolation Forest model for each variable. Finally, I removed the outlier values from each numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-theme",
   "metadata": {},
   "source": [
    "Message nick@connect.earth any questions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
